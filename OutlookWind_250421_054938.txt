import pandas as pd
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Step 1: Create the dataset
data = {
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain',
                'Sunny', 'Overcast', 'Overcast', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain', 'Sunny', 'Rain'],
    'Wind':    ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak',
                'Strong', 'Strong', 'Weak', 'Strong', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong'],
    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',
                   'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes']
}

df = pd.DataFrame(data)

# Step 2: Encode categorical values
le = LabelEncoder()
df['Outlook'] = le.fit_transform(df['Outlook'])  # Sunny=2, Overcast=0, Rain=1
df['Wind'] = le.fit_transform(df['Wind'])        # Weak=1, Strong=0
df['PlayTennis'] = le.fit_transform(df['PlayTennis'])  # No=0, Yes=1

# Step 3: Split features and target
X = df[['Outlook', 'Wind']]
y = df['PlayTennis']

# Step 4: Train Decision Tree
clf = DecisionTreeClassifier(criterion='entropy')  # or use 'gini'
clf.fit(X, y)

# Step 5: Display the decision rules
tree_rules = export_text(clf, feature_names=['Outlook', 'Wind'])
print(tree_rules)

# Optional: Predict and evaluate
y_pred = clf.predict(X)
accuracy = accuracy_score(y, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")